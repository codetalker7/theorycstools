[["conditional-distributions.html", "Chapter 2 Conditional Distributions", " Chapter 2 Conditional Distributions [Sunday 18 May 2025 02:01:50 AM] Conditional distributions are one of the most important constructions of modern probability. However, there are multiple notions of it (which are similar, but need slightly different treatments mathematically, though most of them have the same essence). In this post, I’ll discuss some of those constructions (and book references where you can read more about them). Some of these abstractions can be really helpful if one comes across situations where naive notions of conditional probability might fail. The prerequisites for this post will be: Basic notions of measure theory; measures, measurable maps etc., and related concepts. The standard Borel \\(\\sigma\\)-algebra on \\(\\mathbb{R}\\). The Lebesgue integral, and some related convergence theorems (monotone, dominated convergence). Also, expected values. All these are standard notions studied in any measure theory course. For these notions, my favourite books are (Rao 2005), (Klenke 2020), (Bogachev 2007) and (Dudley 2004); I recommend the reader to go through all these books and see the minor differences in their treatments. References Bogachev, Vladimir I. 2007. Measure Theory, Volume 1. Springer. Dudley, R. M. 2004. Real Analysis and Probability. Klenke, Achim. 2020. Probability Theory: A Comprehensive Course. 3rd ed. Springer. Rao, M. M. 2005. Conditional Measures and Applications. 2nd ed. "],["overview-1.html", "2.1 Overview", " 2.1 Overview We’ll look at three types of conditional distributions, depending on the type of objects we condition on: sets, \\(\\sigma\\)-algebras (or random variables), and sets of measure \\(0\\). Different applications require different levels of conditioning; in extreme cases, one may have to condition on impossible events for the sake of theoretical analysis. Typically, most courses on probability theory cover only the first level of conditioning (i.e conditioning on sets of positive measure). "],["conditioning-on-sets-of-positive-measure.html", "2.2 Conditioning on sets of positive measure", " 2.2 Conditioning on sets of positive measure This is probably the easiest and most intuitive notion of conditionals. Intuitively, this construction allows us to condition on events (or sets). Suppose \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) is a probability space, and let \\(B\\in\\mathcal{A}\\) be a set of positive measure (i.e., \\(\\mathbb{P}(B) &gt; 0\\)). In that case, we can define a new probability measure \\(\\mathbb{P}(\\cdot | B)\\) on \\(\\mathcal{A}\\) by the following (high school conditional measure): \\[ \\begin{aligned} \\mathbb{P}(A | B) := \\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)} \\end{aligned} \\] It is straightforward to verify that this is a probability measure on \\(\\mathcal{A}\\) . Note that, this notion of the conditional probability gives us a measure, and not a random variable, unlike some other notions of conditional expectations that we’ll see. "],["conditioning-on-sigma-algebras-and-random-variables.html", "2.3 Conditioning on \\(\\sigma\\)-algebras and random variables", " 2.3 Conditioning on \\(\\sigma\\)-algebras and random variables The next level of abstraction comes from a simple application: we want to condition on random variables (or, measurable maps), or more generally, \\(\\sigma\\)-algebras. Intuitively, suppose \\(X\\) and \\(Y\\) are random variables (in some probability space). What should conditioning \\(X\\) on \\(Y\\) mean? One way to think of it is this: if we’re given enough information about \\(Y\\), what is the best guess we can make for \\(X\\)? This guess is captured by the conditional expectation \\(\\mathbb{E}[X | Y]\\). Also, note that since we don’t condition on a specific value of \\(Y\\), we expect this object to itself be random. Let’s now see the more general conditional expectation, which conditions a random variable on a \\(\\sigma\\)-algebra. Let \\(X\\) be a random variable on a probability space \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\), and assume that \\(X\\in\\mathcal{L}^1(\\Omega, \\mathcal{A}, \\mathbb{P})\\) (i.e., \\(X\\) is Lebesgue integrable). Let \\(\\mathcal{F}\\subset\\mathcal{A}\\) be a sub-\\(\\sigma\\)-algebra. Again, the question we want to ask is: given \\(\\mathcal{F}\\), what is the best guess we can make about \\(X\\)? We’ll denote this guess by \\(\\mathbb{E}[X | \\mathcal{F}]\\). To that end, we posit that \\(\\mathbb{E}[X | \\mathcal{F}]\\) is itself a random variable. Moreover, it turns out that, to get the best guess of \\(X\\) given \\(\\mathcal{F}\\), it is enough to be able to take averages of \\(X\\) over sets in \\(\\mathcal{F}\\). This leads us to a definition. Definition 2.1 (Conditional Expectation) A random variable \\(Y\\) is called a conditional expectation of \\(X\\) given \\(Y\\), denoted by \\(\\mathbb{E}[X | \\mathcal{F}]\\), if the following are true: \\(Y\\) is \\(\\mathcal{F}\\)-measurable. For any \\(A\\in\\mathcal{F}\\), we have that \\(\\mathbb{E}[X1_A] = \\mathbb{E}[Y1_A]\\). Intuitively, this is just spelling out the fact that, restricted to sets in \\(\\mathcal{F}\\), we can average out \\(X\\) via it’s \\(\\mathcal{F}\\)-measurable proxy \\(Y\\). Taking this a step further, if \\(X\\) and \\(Y\\) are random variables, we define \\[ \\begin{aligned} \\mathbb{E}[X | Y] := \\mathbb{E}[X | \\sigma(Y)] \\end{aligned} \\] It turns out that, under our assumptions, conditional expectations exist upto equality almost surely. Conditional expectations have many interesting properties (aka linearity, tower property, etc.), which I will not mention here. Readers are free to go through the given references to know more about them. "],["regular-conditional-distributions.html", "2.4 Regular conditional distributions", " 2.4 Regular conditional distributions We now come to the third type of conditioning: conditioning on sets of measure \\(0\\). Note that none of the constructions in the previous sections can handle this case. Here’s a simple use-case: consider a simple experiment where we sample a randomly generated number in \\((0, 1)\\), which is uniformly distributed. Call this number \\(X\\) (a random variable). Followed by this experiment, we then run a Bernoulli trial with success probability \\(x\\). How do we formally define the expectation of the second random variable, conditioned on a particular value \\(X = x\\)? Note that one cannot simply condition on a point event \\(X = x\\), since for continuous distributions this event may have measure \\(0\\). This brings us to the notion of regular conditional distributions. At a high level, this construction formalizes everything we need to condition on point-events. To discuss this construction, we’ll need some additional tools which I’ll introduce next. 2.4.1 The Factorization Lemma Before we discuss this, let me mention the so called factorization lemma for measurable maps: Theorem 2.1 (Factorization Lemma) Let \\((\\Omega&#39;, \\mathcal{A}&#39;)\\) be a measurable space and let \\(\\Omega\\) be a non-empty set. Let \\(f:\\Omega\\to\\Omega&#39;\\) be a map. A map \\(g:\\Omega\\to\\mathbb{R}\\) is \\(\\sigma(f)\\)-\\(\\mathcal{B}(\\mathbb{R})\\) measurable if and only if there is a measurable map \\(\\varphi:(\\Omega&#39;, \\mathcal{A}&#39;)\\to(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))\\) such that \\(g = \\varphi\\circ f\\). In simple words, checking whether a map \\(g\\) is \\(\\sigma(f)\\)-measurable is equivalent to checking whether \\(g\\) factors through the space \\((\\Omega&#39;, \\mathcal{A}&#39;)\\) nicely. 2.4.2 Transition Kernels The next tools we’ll introduce are the so called transition kernels, also called Markov kernels in stochastic settings. These should be thought of as a generalization of Markovian transitions: we’re given a current state, and we can follow transitions to other states defined by some distribution. Markov chains usually consider a single state space; on the other hand, Markov kernels will consider transitions between two measurable spaces. In the following definition, we interpret the first argument of the kernel function as the current state, and the second argument as the target state. Definition 2.2 (Transition Kernels) Let \\((\\Omega_1, \\mathcal{A}_1)\\) and \\((\\Omega_2, \\mathcal{A}_2)\\) be measurable spaces. A map \\(\\kappa:\\Omega_1\\times \\mathcal{A}_2\\to[0, \\infty]\\) is called a transition kernel (from \\(\\Omega_1\\) to \\(\\Omega_2\\)) if the following hold: \\(\\omega_1\\mapsto \\kappa(\\omega_1, A_2)\\) is \\(\\mathcal{A}_1\\)-measurable for any \\(A_2\\in\\mathcal{A}_2\\). \\(A_2\\mapsto \\kappa(\\omega_1, A_2)\\) is a measure on \\((\\Omega_2, \\mathcal{A}_2)\\) for any \\(\\omega_1\\in\\Omega_1\\). If in 2, the measure is a probability measure for all \\(\\omega_1\\), \\(\\kappa\\) is called a Markov/stochastic kernel. Let’s look at the definition a bit more closely: observe that point 2 formalizes our notion of conditioning on outcomes of random variables. To see this, we assume that \\(\\omega_1\\in\\Omega_1\\) is the outcome of some random variable, and it defines a measure on the measurable space \\((\\Omega_2, \\mathcal{A}_2)\\). This measure is exactly what we’ll need as our conditional distribution. Point 1 just ensures that \\(\\kappa\\) is also well-behaved w.r.t the first argument (i.e the outcomes of a random variable); we just need measurability w.r.t the first argument. 2.4.3 Defining regular conditional distributions We now have all the tools necessary to complete the construction. Definition 2.3 (Regular Conditional Distributions) Let \\(Y\\) be a random variable on \\((\\Omega, \\mathcal{A})\\) taking values in a measurable space \\((E, \\mathcal{E})\\). Let \\(\\mathcal{F}\\subset \\mathcal{A}\\) be a sub-\\(\\sigma\\)-algebra. A stochastic kernel \\(\\kappa_{Y, \\mathcal{F}}\\) from \\((\\Omega, \\mathcal{F})\\) to \\((E, \\mathcal{E})\\) is called a regular conditional distribution of \\(Y\\) given \\(\\mathcal{F}\\) if \\(\\kappa_{Y,\\mathcal{F}}(\\cdot, B)\\) is a version of \\(\\mathbb{P}[Y\\in B|\\mathcal{F}](\\cdot)\\), i.e we have \\[ \\begin{aligned} \\kappa_{Y,\\mathcal{F}}(\\omega, B) &amp;= \\mathbb{P}[Y\\in B|\\mathcal{F}](\\omega) \\end{aligned} \\] for \\(\\mathbb{P}\\)-almost all \\(\\omega\\in\\Omega\\) and for all \\(B\\in\\mathcal{E}\\). It must be pointed out that these distributions don’t always exist; infact, some nice structure is needed on the value space \\(E\\). It turns out a nice choice of \\(E\\) is to let it be a Polish space. Through the above definition, we can now take conditional probabilities w.r.t point values \\(\\omega\\in\\Omega\\). However, we still need to extend this construction to conditioning on point-values taken by some random variable; this is exactly what we’ll do next. Extension to conditioning on point-values of random variables. Let \\((\\Omega, \\mathcal{A})\\) be a measurable space. Let \\(X, Y\\) be random variables on this space taking values in measurable spaces \\((E&#39;, \\mathcal{E}&#39;)\\) and \\((E, \\mathcal{E})\\) respectively. We want to define a notion of a regular conditional distribution of \\(Y\\) with respect to \\(X\\); naturally, we’ll use the Definition 2.3 with \\(\\mathcal{F} = \\sigma(X)\\). Particularly, we’ll define a stochastic kernel \\(\\kappa_{Y, X}:E&#39;\\times\\mathcal{E}\\to[0, \\infty)\\). This will allow us to then take conditional probabilities as follows: \\[ \\begin{aligned} \\mathbb{P}[Y\\in A|X = x] := \\kappa_{Y, X}(x, A) \\end{aligned} \\] where \\(A\\in \\mathcal{E}\\) and \\(x\\in E&#39;\\). So, assume that a regular conditional distribution \\(\\kappa_{Y, \\sigma(X)}:\\Omega\\times\\mathcal{E}\\to[0, \\infty)\\) exists in the sense of Definition 2.3. Note that \\(\\sigma(X)\\subset \\Omega\\). For this construction, we’ll need another assumption, namely that \\(X(\\Omega)\\in\\mathcal{E}&#39;\\), i.e \\(X(\\Omega)\\) is a measurable set itself. In that case, we have the following: Note that the map \\(\\kappa_{Y, \\sigma(X)}(\\omega, A)\\) as a map of the argument \\(\\omega\\) is \\(\\sigma(X)\\)-measurable, by definition, for every \\(A\\in\\mathcal{E}\\). So, by the Factorization Lemma (Theorem 2.1), there is a map \\(\\kappa_{Y, X}(\\cdot, A):(E&#39;, \\mathcal{E}&#39;)\\to[0, \\infty)\\) such that \\(\\kappa_{Y, \\sigma(X)}\\) factors through \\((E&#39;, \\mathcal{E}&#39;)\\) via \\(\\kappa_{Y, X}\\), i.e we have \\(\\kappa_{Y, \\sigma(X)}(\\omega, A) = \\kappa_{Y, X}(X(\\omega), A)\\) for all \\(\\omega\\in\\Omega\\). Also, \\(\\kappa_{Y, X}(\\cdot, A)\\) is \\(\\mathcal{E}&#39;\\)-measurable for all \\(A\\in\\mathcal{E}\\). Clearly, this is one step in defining the required kernel. Note that, for a fixed \\(x\\in X(\\Omega)\\), the map \\(A\\mapsto\\kappa_{Y, X}(x, A)\\) for \\(A\\in\\mathcal{E}\\) is a probability measure on \\((E, \\mathcal{E})\\), since it equals to \\(\\kappa_{Y, \\sigma(X)}(\\omega, A)\\) for any choice of \\(\\omega\\in X^{-1}(x)\\). However, we still need to deal with \\(x\\notin X(\\Omega)\\). To that end, take any arbitrary probability measure \\(\\mu\\) on \\((E, \\mathcal{E})\\). The trick is to map all \\(x\\notin X(\\Omega)\\) to this measure. Particularly, define the map \\(\\kappa&#39;_{Y, X}(x, A) = \\kappa_{Y, X}(x, A)\\boldsymbol{1}_{x\\in X(\\Omega)} + \\mu(A)\\boldsymbol{1}_{x\\notin X(\\Omega)}\\). Since \\(X(\\Omega)\\in\\mathcal{E}\\) the maps \\(\\boldsymbol{1}_{x\\in X(\\Omega)}\\) and \\(\\boldsymbol{1}_{x\\notin X(\\Omega)}\\) are both \\(\\mathcal{E}&#39;\\)-measurable, and so is the defined map \\(\\kappa&#39;_{Y, X}(\\cdot, A)\\). So this completes our construction! Finally, we can use the kernel \\(\\kappa&#39;_{Y, X}(\\omega, A)\\) to take conditional probabilities, where we condition on point-values \\(X = x\\). Bogachev, Vladimir I. 2007. Measure Theory, Volume 1. Springer. Dudley, R. M. 2004. Real Analysis and Probability. Klenke, Achim. 2020. Probability Theory: A Comprehensive Course. 3rd ed. Springer. Rao, M. M. 2005. Conditional Measures and Applications. 2nd ed. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
